% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Machine Learning in Genomics: Containerised tutorials demonstrating best practises, pitfalls, and reproducibility},
  pdfauthor={ Sach Nehal},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Machine Learning in Genomics: Containerised tutorials demonstrating best practises, pitfalls, and reproducibility}
\author{Sach Nehal}
\date{2024-08-07}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{About}\label{about}
\addcontentsline{toc}{chapter}{About}

Applied machine learning utilising vast amounts of data has aided in pattern identification, predictive analytics, and solving complex problems across a multitude of fields. Solving these complex problems within these fields, researchers would find differing answers to the following questions; \textbf{what machine learning techniques can we apply to the problem, how do we apply the techniques in the context of this field, and why do we need to apply them in this way?} In any case, applied machine learning requires an interdisciplinary understanding of computing techniques and the field in question.

The aim of this project is to provide you with \textbf{a set of reproducible, containerized tutorials that include all necessary data, code, and descriptions to replicate key results, along with demonstrations of common pitfalls, in the field of genomics}. It is designed for users with knowledge of machine learning but little or no background in biology as a process to learn about applying machine learning techniques in genomics.

\part{Introduction}\label{part-introduction}

\chapter{Epigenetic Data}\label{epigenetic-data}

\section{What is epigenetic data?}\label{what-is-epigenetic-data}

As you may already know, typically all of the cells in your body contain the same DNA. How, then, do we have different cell types in our body? Your DNA contains a script that is able to produce the proteins required for each specific cell in your body. Which proteins, and subsequently which cells are made, depends on gene expression and regulation, i.e.~``the way each cell deploys its genome.''\footnote{\citet{ralston2008}}

\textbf{\emph{Epigenetic data}} arises from ``the study of heritable and stable changes in gene expression that occur through alterations in the chromosome rather than in the DNA sequence.''\footnote{\citet{nora2023}}

\includegraphics{images/Epigenetic_Mechanisms.png}

\href{https://commonfund.nih.gov/sites/default/files/epigeneticmechanisms.pdf}{commonfund.nih.gov}

The image above shows quite simply the basics of genetic structures. Several more complex processes are involved during cell replication such as DNA transcription and translation in order to make proteins. A key takeaway in coming closer to understanding gene expression is that \textbf{Chromatin} is a complex structure made up of DNA wound around histone proteins, with some segments of DNA being accessible/inaccessible to further processes. \textbf{Euchromatin} refers to the accessible state, while \textbf{Heterochromatin} refers to a chromatin state in which DNA cannot be transcribed (inaccessible).\footnote{\citet{shahid2023}} There are many different epigenetic modifications that affect chromatin accessibility.

Some common epigenetic modifications include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{DNA Methylation}: Addition of methyl groups to DNA, affecting gene expression regulation\footnote{\citet{nora2023}}.
\item
  \textbf{Histone Modifications}: Chemical changes to histone proteins that DNA wraps around, including acetylation, methylation, or phosphorylation. These changes influence chromatin structure and gene accessibility.\footnote{\citet{Kouzarides2007}}
\item
  \textbf{Chromatin Accessibility}: Regions of open chromatin that are accessible to transcription factors (special types of proteins that bind to DNA sequences and regulate gene expression) further dictate which regions of DNA can be expressed\footnote{\citet{melanie2021}}.
\end{enumerate}

In studying gene expression and epigenetic modifications, we aim to more closely understand biological mechanisms that regulate development, disease, and how cells respond to epigenetic factors.

\subsection{What Does DNA Look Like?}\label{what-does-dna-look-like}

As illustrated in the image above, DNA is structured as a double helix, with two complementary strands intertwined to form the characteristic helical shape. DNA consists of an extremely long sequence composed of four types of nucleotides: Adenine (A), Cytosine (C), Thymine (T), and Guanine (G).

According to the National Cancer Institute (USA), nucleotides within the DNA double helix form complementary pairs---Adenine pairs with Thymine, and Guanine pairs with Cytosine\footnote{\citet{ncidefinitions}}. These pairs are commonly referred to as base pairs (bps). For example, if one strand of the double helix has the sequence ``ATCGG'', the complementary strand will have the sequence ``TAGCC''.

Genes are sequences of DNA located at specific positions on chromosomes and can vary in length. Each gene encodes information necessary for producing proteins or RNA molecules, which are essential for the structure, function, and regulation of an organism\footnote{\citet{ncidefinitions}}. The complete set of genetic material in an organism is known as its genome.

\includegraphics{images/dna_sequence.png}

Image highlighting part of a \href{https://www.researchgate.net/profile/Pratik-Kanani/publication/341901570/figure/fig1/AS:898621708984321@1591259519483/A-human-DNA-and-Part-of-DNA-sequence-28-29.jpg}{dna sequence and base pairs}.\footnote{\citet{kanani2020}}

\subsection{Common Epigenetic Sequencing Techniques:}\label{common-epigenetic-sequencing-techniques}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\emph{ATAC-Seq}} (Assay for Transposase-Accessible Chromatin with Sequencing):
  o\texttt{Measures\ chromatin\ accessibility\ to\ identify\ open\ regions\ of\ the\ genome\ where\ transcription\ factors\ can\ bind.}
  o\texttt{Output:\ Peaks\ indicating\ accessible\ chromatin\ regions.}
\item
  \textbf{\emph{ChIP-Seq}} (Chromatin Immunoprecipitation Sequencing):
  o\texttt{Used\ to\ identify\ DNA\ regions\ bound\ by\ specific\ proteins\ (e.g.,\ transcription\ factors,\ histones\ with\ specific\ modifications).}
  o\texttt{Output:\ Peaks\ indicating\ binding\ sites\ or\ modification\ locations.}
\end{enumerate}

\section{What does epigenetic data look like?}\label{what-does-epigenetic-data-look-like}

Epigenetic data can be represented in various forms, depending on the type of modification being studied and the methods used to gather the data. \textbf{ATAC-Seq} and \textbf{ChIP-Seq} are the common methods I will focus on, but there are others that may produce different forms of data, such as WGS (whole-genome sequencing) which produces nucleotide sequencing data, or Bisulfite conversion of DNA producing data on methylation levels across the genome.

\subsection{Representing epigenetic data}\label{representing-epigenetic-data}

Epigenetic data originates from sequencing methods such as ATAC-Seq or ChIP-Seq experiments. The initial experiments produce raw sequencing reads (fragments), which are then aligned to a reference genome. By aligning these sequences, we can aggregate the reads into regions where they `pile up' to form peaks, indicating areas of significant biological activity or modification. This can be done per base across the genome, or per gene. Additionally, we could also examine mismatches where a read's base differs from the genome's base, and use them to identify SNPs (\href{https://www.cancer.gov/publications/dictionaries/genetics-dictionary/def/single-nucleotide-polymorphism}{single nucleotide polymorphisms})\footnote{\citet{ncidefinitions}}. This mismatch information can be recorded in a table showing the position, type of mismatch, and the number of reads supporting each mismatch.\footnote{\citet{akalin2020}}

\includegraphics{images/sequencing_pipeline.png}

Image showing the \href{https://compgenomr.github.io/book/images/HTseq.png}{sequencing pipeline} from high-throughput sequencing methods\footnote{\citet{akalin2020}}.

1. \textbf{\emph{Raw Sequence Reads:}}
o\texttt{These\ are\ the\ basic\ output\ of\ sequencing\ experiments,\ such\ as\ those\ from\ ChIP-Seq\ or\ ATAC-Seq.}
o\texttt{Reads\ are\ processed\ and\ aligned\ to\ a\ reference\ genome\ before\ undergoing\ peak\ calling.}

Lets look at what a few lines of raw sequence read data consists of:
The data is taken from Encode Experiment \href{https://www.encodeproject.org/experiments/ENCSR817LUF/}{ENCSR817LUF} (chIP-Seq). The accession ID of the raw sequence read data is \href{https://www.encodeproject.org/files/ENCFF397NRK/}{ENCFF397NRK}. Genomic data comes in many file formats. This specific raw sequence read data is a compressed FASTQ file.

Note: The script I used involved streaming the data directly from a URL using the requests library. While files containing genomic data are generally quite large, for computational efficiency it is recommended that data be downloaded locally.

\begin{verbatim}
## ID: B091JABXX110402:1:2204:12975:184709
## Sequence: GTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGG
## Quality Scores: [31, 30, 30, 32, 36, 37, 36, 32, 33, 32, 35, 36, 37, 33, 33, 34, 37, 37, 36, 33, 34, 30, 37, 37, 37, 33, 34, 33, 38, 33, 33, 32, 33, 35, 37, 36]
## 
## ID: B091JABXX110402:1:2205:18641:8399
## Sequence: GGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAG
## Quality Scores: [22, 27, 31, 30, 30, 33, 31, 32, 31, 31, 24, 36, 37, 36, 33, 34, 33, 37, 37, 32, 32, 34, 22, 37, 36, 30, 23, 35, 27, 29, 28, 28, 23, 31, 26, 35]
## 
## ID: B091JABXX110402:1:1207:12202:100922
## Sequence: AGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTT
## Quality Scores: [33, 33, 36, 37, 31, 34, 34, 36, 37, 36, 29, 33, 35, 36, 39, 37, 32, 33, 35, 37, 34, 37, 33, 34, 36, 38, 39, 25, 32, 35, 36, 38, 37, 38, 32, 32]
\end{verbatim}

As you can see, each data entry is a DNA sequence (read). While I'm only showing the first three entries, for each experiment there are millions of sequencing reads. The quality scores indicate the confidence of each base call in the sequence. Higher scores suggest higher confidence. The scores are in Phred format, where a score of 20 corresponds to a 99\% base call accuracy, 30 corresponds to 99.9\%, 40 corresponds to 99.99\%, and so on.\footnote{\citet{green}}
2. \textbf{\emph{Peak Calling:}}
o\texttt{A\ method\ used\ to\ identify\ regions\ in\ the\ genome\ where\ there\ is\ significant\ enrichment\ of\ sequencing\ reads.\ This\ indicates\ the\ presence\ of\ DNA-protein\ interactions\ (e.g.,\ transcription\ factor\ binding\ sites\ or\ accessible\ chromatin\ regions).}
o\texttt{Peaks\ represent\ areas\ where\ epigenetic\ marks\ or\ chromatin\ accessibility\ are\ concentrated.}

A common peak calling algorithm is \href{https://hbctraining.github.io/Intro-to-ChIPseq/lessons/05_peak_calling_macs.html}{MACS2}. Essentially, aligned sequencing reads are aggregated into regions where they `pile up' to form peaks as a read count per base. The outputs typically include signal p-values or fold change over control values, with the continuous -log10(p-value) often averaged over bins (e.g., 25 base pairs). While MACS2 is traditionally used in ChIP-seq experiments, it is also applied to ATAC-seq to identify significant peaks and assess their enrichment. In ChIP-seq, broad peaks often represent histone modifications covering entire gene bodies, while narrow peaks are indicative of transcription factor binding sites\footnote{\citet{wilbanks2010}}. In ATAC-seq, the peaks primarily reflect regions of open chromatin.

\textbf{\emph{Representing Peaks:}}
o \textbf{\emph{P-value or Fold-change:}}
P-value: Indicates the statistical significance of the peak, helping to distinguish true peaks from background noise.
Fold-change: Represents the difference in read density between treated and control samples, indicating the strength of the signal.

\includegraphics{images/coverage_p.png}
This image shows the signal p-value coverage over a small region (11,176bps) in chromosome one from Encode Experiment \href{https://www.encodeproject.org/experiments/ENCSR817LUF/}{ENCSR817LUF} (The same chIP-Seq experiment we saw the raw sequence reads from). For further context, experiment ENCSR817LUF targets the H3K36me3 histone modification in brain tissue. The experiment aims to map the locations where the H3K36me3 histone modification is present along the genome. Therefore the peaks represent regions of the genome where the the H3K36me3 histone modification is enriched compared to the background or control. The accession ID of the signal p-value data is \href{https://www.encodeproject.org/files/ENCFF601VTB/}{ENCFF601VTB}. Genomic data comes in many file formats. This specific signal p-value data is a bigWig file.
o \textbf{\emph{Types of Peaks:}}
Categorical Peaks: Simple yes/no indication of a peak's presence.
Continuous Peaks: More nuanced representation that includes the intensity or enrichment level of the peak, often visualized as a signal track.
Thresholded/Pseudoreplicated Peaks: Usually categorical, these peaks are of high confidence regions from multiple replicates (experiments) or pseudoreplicates (artificial data splits), to ensure reliability and reproducibility.

\textbf{\emph{Example Data Pipeline}}

\href{https://www.encodeproject.org/experiments/ENCSR817LUF/}{encodeproject.org}

This is an example data pipeline from Encode Experiment \href{https://www.encodeproject.org/experiments/ENCSR817LUF/}{ENCSR817LUF}, the same chIP-Seq experiment we saw the raw sequence reads, and signal p-value coverage from. The yellow bubbles represent downloadable data sets of different types, while the blue boxes represent step types (e.g.~peak calling). In the left column are multiple data sets of raw sequence reads, which then undergo data quality steps before being aligned (first blue box) to the reference human genome GRCh38 (denoted by ENCFF110MCL below the reads). The next steps include Peak calling (categorical peaks) and signal generation (continuous peaks) to produce the data we normally use in our machine learning models. This data pipeline process aids in normalisation, noise reduction, and dimensionality reduction of the data.

\subsection{Transformations to stop extreme p-values}\label{transformations-to-stop-extreme-p-values}

When utlising genomic data which incorporates p-values, it is important to consider and deal with extreme p-values. One way this is done is through using an Arcsinh-transformation (inverse hyperbolic sine).
\(\text{arsinh}(x) = \ln \left( x + \sqrt{x^2 + 1} \right)\)

The arcsinh-transformation as a logarithmic function helps in reducing the significance of outliers and sequencing depth while maintaining variance by compressing the range of the data. This transformation can be used in the data preprocessing stage. The graph below visualises how the transformation works. While extreme values are transformed logarithmically, the smaller values are barely transformed as the function for smaller values is more linear in nature.

\includegraphics{images/arcsinh.png}

Plot of \href{https://miro.medium.com/v2/resize:fit:1100/format:webp/1*glJtHk1HRZpYHsk79QxgwQ.png}{Arcsinh Transformation} compared to a log function, made with Desmos available under \href{https://miro.medium.com/v2/resize:fit:1100/format:webp/1*glJtHk1HRZpYHsk79QxgwQ.png}{CC BY-SA 4.0.} Text, arrows, and box shape added to image.

\section{Sources of epigenetic data}\label{sources-of-epigenetic-data}

There are numerous public data banks which contain genomic datasets ready to be downloaded.
\href{https://projects.ensembl.org/blueprint/}{Blueprint}
Blueprint's genomic datasets are focused on gene expression in healthy and diseased cells mostly relating to haematopoietic cells (cells which develop into different types of blood cells).

\href{https://www.ncbi.nlm.nih.gov/geo/roadmap/epigenomics/}{Roadmap}
The National Institute of Health's Roadmap Epigenomics Project contains sample datasets from multiple experiements as well as reference and mapping datasets.

\href{https://www.encodeproject.org/}{Encode}
The Encode Project contains a large amount of publicly available genomic data easily filtered and downloaded. The genomic data used in this markdown book is sourced from Encode.

The largest genomic data bank is the \href{https://www.ukbiobank.ac.uk/}{UK Biobank}, however they require that you apply for access to their datasets.

\section{UCSC'S Genome Browser}\label{ucscs-genome-browser}

The UCSC Genome Browser is a powerful and versatile tool that allows the visualisation and exploration of many sets of genomic data, especially bigWig files. It offers an extensive collection of genome assemblies, annotation tracks, and functional data, enabling users to examine gene structures, regulatory elements, and genetic variations. With its user-friendly interface and customisable display options, the UCSC Genome Browser facilitates detailed genomic analyses and supports a wide range of applications in genomics and bioinformatics. Whether you're investigating gene functions, exploring genetic variants, or studying comparative genomics, the UCSC Genome Browser serves as an essential resource for understanding complex genomic information. It is also possible to load and visualise genomic data from other sources such as Encode. While the visualisations are extensive, as you can explore below, the browser can be quite overwhelming for first time users.

The following is an example of what the same chIP-Seq data targeting the H3K36me3 histone modification in brain tissue looks like using UCSC's Genome Browser. The pseudoreplicated peaks represent categorically, the significant locations along the genome where the H3K36me3 histone modification is present.

\href{https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr1\%3A11084744\%2D11095920&hgsid=2307713234_Kap236Tjt6ZGnnNrXMkIhq2Ajn27}{UCSC Genome Browser}

The following is an example of ATAC-Seq data from an experiment on T-helper 17 cells (a type of immune system cell). Recall that the ATAC-Seq method aims to find chromatin regions that are accessible for transcription factor binding. The p-value and fold change graphs show continuous peaks, while the IDR thresholded peaks and pseudoreplicated peaks represent the significant locations of accessible chromatin along the genome.

\href{https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr1\%3A88379533\%2D113275174&hgsid=2307721306_mcnECXS4Hy0fNQ4yz3ZQTL7nimkW}{UCSC Genome Browser}

\section{Handling bigWig files}\label{handling-bigwig-files}

BigWig files can be quite tricky to deal with. However, libraries such as pyBigWig enable easier access of data. In order to understand how to handle the data pre-processing stage, I have created a jupyter notebook tutorial. The tutorial begins using UCSC's programs to quickly understand the genomic data within BigWigs, before using the pyBigWig library to simply extract BigWig data.

The final part of the tutorial uses the pyBigWig library to load, filter, and split BigWig data into training, validation, and test sets. The data consists of signal p-values from ChIP-seq experiments, processed using the MACS2 tool, which outputs signals averaged over 25 base pair bins. We will re-average these signals to a resolution of 32 base pairs. Additionally, we will implement threshold-based filtering and consistent data splits to understand how to ready data for a model.

Tutorial 1: Dealing with bigWigs (interactive)

Tutorial 1: Dealing with bigWigs (nbviewer)

\section{Data loaders and simplifying pre-processing}\label{data-loaders-and-simplifying-pre-processing}

Data loaders are scripts/functions to load batches of data into your model. They are crucial in machine learning because they simplify how data is fed into models, making the whole process smoother and more efficient. This becomes especially important with the large datasets used in genomic studies, where managing and processing data manually would be cumbersome. By automating these tasks, data loaders help ensure that data is processed efficiently, allowing for faster and more effective model training. While there are existing github repositories with data loaders, such as \href{https://kipoi.org/kipoiseq/dataloaders/}{``Kipoi Dataloader''}, and \href{https://github.com/pfizer-opensource/bigwig-loader/blob/main/README.md}{``Dataloader for BigWig files''}.\footnote{\citet{retel_fast_2024}}, depending on the data used and model you build, they won't cover all of the use cases.

\section{Dealing with missing data (oversampling, undersampling, weighting)}\label{dealing-with-missing-data-oversampling-undersampling-weighting}

\part{Training models with DNA input}\label{part-training-models-with-dna-input}

\chapter{Loss functions, and peak metrics}\label{loss-functions-and-peak-metrics}

\chapter{Base pair averaging}\label{base-pair-averaging}

\chapter{Training tricks}\label{training-tricks}

\chapter{Choosing which genomic regions to train on}\label{choosing-which-genomic-regions-to-train-on}

\chapter{Effect of differences in sequencing depths}\label{effect-of-differences-in-sequencing-depths}

\chapter{Reproducibility of machine learning models}\label{reproducibility-of-machine-learning-models}

\section{Seeding}\label{seeding}

\section{Dashboarding}\label{dashboarding}

\chapter{Testing}\label{testing}

\part{Software libraries for model building}\label{part-software-libraries-for-model-building}

\chapter{gReLU}\label{grelu}

\chapter{Kipoi}\label{kipoi}

\chapter{Weights and Biases}\label{weights-and-biases}

\part{ML pitfalls in genomics}\label{part-ml-pitfalls-in-genomics}

\chapter{Pitfalls overview}\label{pitfalls-overview}

\section{Distributional differences}\label{distributional-differences}

\section{Dependent examples}\label{dependent-examples}

\section{Confounding}\label{confounding}

\section{Leaky pre-processing}\label{leaky-pre-processing}

\section{Unbalanced classes}\label{unbalanced-classes}

\section{Balancing the proportion of peaks / no-peaks in validation sets}\label{balancing-the-proportion-of-peaks-no-peaks-in-validation-sets}

\part{Model interpretability}\label{part-model-interpretability}

\chapter{Creating and visualising a simple model}\label{creating-and-visualising-a-simple-model}

\chapter{TF mo-Disco}\label{tf-mo-disco}

\part{Using existing models}\label{part-using-existing-models}

\chapter{Using the gReLU model zoo}\label{using-the-grelu-model-zoo}

\chapter{Fine tuning of Enformer}\label{fine-tuning-of-enformer}

\part{Predicting in novel cell types}\label{part-predicting-in-novel-cell-types}

\chapter{Incorporating ATAC-seq info}\label{incorporating-atac-seq-info}

\chapter{Use of cell type averages}\label{use-of-cell-type-averages}

\part{More complex models}\label{part-more-complex-models}

\chapter{Training multi-headed models}\label{training-multi-headed-models}

\chapter{Training siamese twin models}\label{training-siamese-twin-models}

  \bibliography{book.bib,packages.bib}

\end{document}
